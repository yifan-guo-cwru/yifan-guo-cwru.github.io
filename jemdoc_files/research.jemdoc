# jemdoc: menu{MENU}{research.html}, nofooter

== Research Projects
This page highlights my selected research projects.

== 2025
~~~
{}{img_left}{./images/research_images/Semi-Sync Protocols.png}{}{280px}{}{}
== SPFERE: Towards Practical Semi-Synchronous On-Device Federated Edge Learning With Fairness and Power Awareness
==== Accepted to IEEE Transactions on Mobile Computing
In this work, we propose SPFERE, a Semi-synchronous Power-aware and FairnEss-Regulated Engine in this paper, designed for power-constrained edge environments and implemented on a real-world edge testbed to support asynchronous model updating, power management, and fairness-aware model aggregation. Specifically, we propose a client grouping-based semi-synchronous aggregation protocol that reduces idle waiting time for power-abundant devices and mitigates stale updates from power-constrained devices, along with our in-depth convergence analysis. Then, we introduce a long short-term memory (LSTM)-based power estimation approach to predict remaining battery voltage for devices with limited communication overhead, enabling early warnings for power dropouts. Lastly, we design fusion-based fairness-aware model aggregation methods to prevent bias by considering device participation frequency and training workload. \n
ðŸ“„ **Paper:** [https://doi.org/10.1109/TMC.2025.3649621 IEEE Xplore Link] \n
ðŸ’» **Code:** [https://github.com/YixinChenYC1999/SPFERE/tree/main GitHub Repository] \n
ðŸŽ¥ **Demo Video:** [https://youtu.be/WQP8dnkH-AM YouTube Demo] \n
~~~

~~~
{}{img_left}{./images/research_images/differences.png}{}{280px}{}{}
== Integrating Independent Layer-Wise Rank Selection with Low-Rank SVD Training for Model Compression: A Theory-Driven Approach
==== Accepted to Proceedings of the Thirty-Fourth International Joint Conference on Artificial Intelligence (IJCAI-25)
In this paper, we design a novel approach by integrating rank selection into the lowrank training process and performing independent layer-wise rank selection under the guidance of a theoretical loss error bound. Specifically, we first conduct a comprehensive theoretical analysis to quantify how low-rank approximations impact the training losses. Building on these insights, we develop an efficient layer-wise rank search algorithm and seamlessly incorporate it into low-rank singular value decomposition (SVD) training. \n
ðŸ“„ **Paper:** [https://www.ijcai.org/proceedings/2025/0589.pdf Paper(PDF)] \n
ðŸ“Œ **Poster:** [../www/files/ijcai25_poster.pdf Poster(PDF)] \n
~~~

== 2024
~~~
{}{img_left}{./images/research_images/CBA_workflow.png}{}{280px}{}{}
== Collusive Backdoor Attacks in Federated Learning Frameworks for IoT Systems
==== Accepted to IEEE Internet of Things Journal
In this article, we propose a novel attack approach, called collusive backdoor attacks (CBAs), which bypasses robust aggregation defense by considering both local backdoor training and post-training model manipulations among collusive attackers. Particularly, we introduce a nontrivial perturbation estimation scheme to add manipulations over model update vectors after local backdoor training and use the Gram-Schmidt process to speed up the estimation process. This makes the magnitude of the perturbed poisoned model to the same level as normal models, evading robust aggregation-based defense while maintaining attack efficacy. After that, we provide a pilot study to verify the feasibility of our perturbation estimation scheme, followed by its convergence analysis. \n
ðŸ“„ **Paper:** [https://ieeexplore.ieee.org/abstract/document/10453350 IEEE Xplore Link] \n
~~~

