# jemdoc: menu{MENU}{research.html}, nofooter

== Research Projects
This page highlights my selected research projects.

== 2025
~~~
{}{img_left}{./images/research_images/Semi-Sync Protocols.png}{}{280px}{}{}
== SPFERE: Towards Practical Semi-Synchronous On-Device Federated Edge Learning With Fairness and Power Awareness
==== Accepted to IEEE Transactions on Mobile Computing
This work focuses on a semi-synchronous fairness-and-power-aware FEL framework with a co-design for learning and communication, and proposes SPFERE, a Semi-synchronous Power-aware and FairnEss-Regulated Engine, designed for power-constrained edge environments and implemented on both a real-world edge testbed and a simulation platform to support asynchronous model updating, power management, and fairness-aware model aggregation.\n
ðŸ“„ **Paper:** [https://doi.org/10.1109/TMC.2025.3649621 Paper(PDF)] \n
ðŸ’» **Code:** [https://github.com/YixinChenYC1999/SPFERE/tree/main GitHub Repository] \n
ðŸŽ¥ **Demo Video:** [https://youtu.be/WQP8dnkH-AM YouTube Demo] \n
~~~

~~~
{}{img_left}{./images/research_images/differences.png}{}{280px}{}{}
== Integrating Independent Layer-Wise Rank Selection with Low-Rank SVD Training for Model Compression: A Theory-Driven Approach
==== Accepted to Proceedings of the Thirty-Fourth International Joint Conference on Artificial Intelligence (IJCAI-25)
In this paper, we design a novel approach by integrating rank selection into the lowrank training process and performing independent layer-wise rank selection under the guidance of a theoretical loss error bound. Specifically, we first conduct a comprehensive theoretical analysis to quantify how low-rank approximations impact the training losses. Building on these insights, we develop an efficient layer-wise rank search algorithm and seamlessly incorporate it into low-rank singular value decomposition (SVD) training. \n
ðŸ“„ **Paper:** [https://www.ijcai.org/proceedings/2025/0589.pdf Paper(PDF)] \n
~~~

== 2024
~~~
{}{img_left}{./images/research_images/CBA_workflow.png}{}{280px}{}{}
== Collusive backdoor attacks in federated learning frameworks for IoT systems
==== Accepted to IEEE Internet of Things Journal
In this article, we propose a novel attack approach, called collusive backdoor attacks (CBAs), which bypasses robust aggregation defense by considering both local backdoor training and post-training model manipulations among collusive attackers. Particularly, we introduce a nontrivial perturbation estimation scheme to add manipulations over model update vectors after local backdoor training and use the Gram-Schmidt process to speed up the estimation process. This makes the magnitude of the perturbed poisoned model to the same level as normal models, evading robust aggregation-based defense while maintaining attack efficacy. After that, we provide a pilot study to verify the feasibility of our perturbation estimation scheme, followed by its convergence analysis. \n
ðŸ“„ **Paper:** [https://ieeexplore.ieee.org/abstract/document/10453350 Paper(PDF)] \n
~~~

